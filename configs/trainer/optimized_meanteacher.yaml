defaults:
  - _self_

method: optimized-mean-teacher

train:
  total_epochs: 200
  validation_interval: 10

init:
  _target_: trainer.MeanTeacherTrainer

  supervised_criterion:
    _target_: torch.nn.MSELoss

  unsupervised_criterion:
    _target_: torch.nn.MSELoss

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 0.001          # tuned learning rate
    weight_decay: 0.005

  # Cosine annealing scheduler (matches other trainers)
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: true
    T_max: 100

  # Mean Teacherâ€“specific hyperparameters
  ema_decay: 0.99                # initial EMA decay
  consistency_weight: 0.01       # gentler consistency pressure
  consistency_rampup_epochs: 50

  # Uncertainty / augmentation hyperparameters
  confidence_threshold: 0.1
  strong_augment_node_noise_std: 0.05
  strong_augment_edge_drop_prob: 0.05
